{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training - Basic Model\n",
    "\n",
    "In this Notebook, we will go through building a basic PyTorch Model for Training, and training it to get results on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "In this project, we will be using PyTorch for Deep Learning. NLP Pre-Processing, however, will be done using Keras's modules, because I prefer the implementation provided in the library. Instead of installing Keras, the relavant modules are imported in as scripts from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "\n",
    "import torch;\n",
    "from torch import nn;\n",
    "from torch.utils.data import Dataset, DataLoader;\n",
    "import torch.nn.functional as F;\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score;\n",
    "\n",
    "import math;\n",
    "from numpy import save, load;\n",
    "import keras_sequence_preprocessing as seq_preprocessing;\n",
    "import keras_text_preprocessing as text_preprocessing;\n",
    "\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import time;\n",
    "\n",
    "from PyTorchTools import EarlyStopping;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_train_text = pd.read_csv('data/augmented_quora_text.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_train_text = quora_train_text.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "We have 2 different types of Word Embeddings we will try in this application: Glove and FastText. To use the specific embedding, run that cell and not the other, as both are loaded in with the same formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOVE Embeddings\n",
    "\n",
    "embeddings_dict = {};\n",
    "with open('../Embeddings/glove.6B/glove.6B.%dd.txt'%(embed_size), 'rb') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTTEXT Embeddings\n",
    "\n",
    "embeddings_dict = {};\n",
    "with open('../Embeddings/crawl-%dd-2M.vec'%(embed_size), 'rb') as f:\n",
    "    for line in f:\n",
    "        splits = line.split();\n",
    "        word = splits[0];\n",
    "        vec = np.asarray(splits[1:], dtype='float32')\n",
    "        \n",
    "        embeddings_dict[word.decode()] = vec;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a Word Index from the embeddings. To quickly do this, we will simply be iterating over the dataset and assigning an integer value to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {};\n",
    "\n",
    "token_num = 0;\n",
    "for row in quora_train_text[['cleaned_text', 'target']].iterrows():\n",
    "    text, label = row[1]\n",
    "    \n",
    "    tokens = [token for token in text.split(' ')];\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in word_index:\n",
    "            word_index[token] = token_num;\n",
    "            token_num = token_num + 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 200000\n",
    "MAX_LEN = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we encode the individual sentences into sequences of integers from the word index. Than Pad them to fixed lengths using post-sequence-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentence, word_index=word_index, max_words=MAX_WORDS):\n",
    "    output = [];\n",
    "    for token in sentence.split(' '):\n",
    "        if (token in word_index) and (word_index[token] < max_words):\n",
    "            output.append(word_index[token]);\n",
    "    return output;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences = [encode_sentences(sent) for sent in quora_train_text['cleaned_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_lengths = [len(x) for x in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = seq_preprocessing.pad_sequences(encoded_sentences, maxlen=MAX_LEN, padding='post', truncating='post');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do training / testing, we will divide the dataset into proper Training and Validation. 85% of the dataset for training, and the remaining 15% fo validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176815, 207674)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_split = int(0.85 * len(quora_train_text));\n",
    "\n",
    "train_ds = padded_sequences[:val_split];\n",
    "val_ds = padded_sequences[val_split:];\n",
    "\n",
    "train_y = quora_train_text.iloc[:val_split]['target'].values;\n",
    "val_y = quora_train_text.iloc[val_split:]['target'].values;\n",
    "\n",
    "train_lens = encoded_lengths[:val_split];\n",
    "val_lens = encoded_lengths[val_split:];\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build an Embeddings Matrix. Each row in the matrix is a vector from Glove / Fasttext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = min(MAX_WORDS, len(word_index))+1;\n",
    "embeddings_matrix = np.zeros((vocab_size, embed_size));\n",
    "\n",
    "for word, posit in word_index.items():\n",
    "    if posit >= vocab_size:\n",
    "        break;\n",
    "        \n",
    "    vec = embeddings_dict.get(word);\n",
    "    if vec is None:\n",
    "        vec = np.random.sample(embed_size);\n",
    "        embeddings_dict[word] = vec;\n",
    "    \n",
    "    embeddings_matrix[posit] = vec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tensor = torch.Tensor(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Data Loader to iterate over during the training process in a fixed batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, encoded_sentences, labels, lengths):\n",
    "        self.encoded_sentences = encoded_sentences;\n",
    "        self.labels = labels;\n",
    "        self.lengths = lengths;\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sentences);\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.encoded_sentences[index, :];\n",
    "        x = torch.LongTensor(x);\n",
    "        \n",
    "        y = self.labels[index];\n",
    "        y = torch.Tensor([y]);\n",
    "        \n",
    "        length = self.lengths[index];\n",
    "        length = torch.Tensor([length]);\n",
    "        \n",
    "        return x, y, length;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QuoraDataset(train_ds, train_y, train_lens);\n",
    "val_dataset = QuoraDataset(val_ds, val_y, val_lens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512;\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True);\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Torch Model will have the following architecture:\n",
    "\n",
    "1. Embeddings Layer\n",
    "2. 1st LSTM Layer\n",
    "2. 1st Dense Fully Connected Layer\n",
    "3. ReLU Activation\n",
    "4. 2nd LSTM Layer\n",
    "5. Global Max-Average Pooling Layer\n",
    "6. 2nd Dense Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_unit = 64):\n",
    "        super(Model, self).__init__();\n",
    "        vocab_size = embeddings_tensor.shape[0];\n",
    "        embedding_dim = embeddings_tensor.shape[1];\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim);\n",
    "        self.embedding_layer.weight = nn.Parameter(embeddings_tensor);\n",
    "        self.embedding_layer.weight.requires_grad = True;\n",
    "        \n",
    "        self.lstm_1 = nn.LSTM(embedding_dim, hidden_unit, bidirectional=True);\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hidden_unit*2, hidden_unit*2);\n",
    "        \n",
    "        self.lstm_2 = nn.LSTM(hidden_unit*2, hidden_unit, bidirectional=True);\n",
    "        \n",
    "        self.fc_2 = nn.Linear(hidden_unit * 2 * 2, 1);\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.embedding_layer(x);\n",
    "        \n",
    "        out, _ = self.lstm_1(out);\n",
    "        \n",
    "        out = self.fc_1(out);\n",
    "        \n",
    "        out = torch.relu(out);\n",
    "        \n",
    "        out, _ = self.lstm_2(out);\n",
    "        \n",
    "        out_avg, out_max = torch.mean(out, 1), torch.max(out, 1)[0];\n",
    "        out = torch.cat((out_avg, out_max), 1);\n",
    "        \n",
    "        out = self.fc_2(out);\n",
    "        return out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding_layer): Embedding(200001, 300)\n",
       "  (lstm_1): LSTM(300, 64, bidirectional=True)\n",
       "  (fc_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lstm_2): LSTM(128, 64, bidirectional=True)\n",
       "  (fc_2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(embeddings_tensor, 64);\n",
    "model = model.to(device);\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a Binary-Cross-Entropy Loss Function, and an Adam Optimizer with a 0.003 Learning Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss();\n",
    "optimizer = torch.optim.Adam(lr=0.003, params = model.parameters());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Now we write the methods to iterate over the data to train and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nn_model, nn_optimizer, nn_criterion, data_loader, val_loader = None, num_epochs = 5, print_ratio = 0.1, verbose=True):\n",
    "    \n",
    "    print_every_step = int(print_ratio * len(train_loader));\n",
    "    \n",
    "    if verbose:\n",
    "        print('Training with model: ');\n",
    "        print(nn_model);\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        epoch_time = time.time();    \n",
    "\n",
    "        f1_scores_train = []\n",
    "\n",
    "        # Enable Training for the model\n",
    "        nn_model.train()\n",
    "        running_loss = 0;\n",
    "\n",
    "        all_ys = torch.tensor(data=[]).to(device);\n",
    "        all_preds = torch.tensor(data=[]).to(device);\n",
    "\n",
    "        for ite, (x, y, l) in enumerate(data_loader):\n",
    "            init_time = time.time();\n",
    "\n",
    "            # Convert our tensors to GPU tensors\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            nn_optimizer.zero_grad()\n",
    "\n",
    "            # Forward Propagation and compute predictions\n",
    "            preds = nn_model.forward(x, l)\n",
    "\n",
    "            # Compute loss against actual values\n",
    "            loss = nn_criterion(preds, y)\n",
    "\n",
    "            # Add predictions and actuals into larger list for scoring\n",
    "            all_preds = torch.cat([all_preds, preds]);\n",
    "            all_ys = torch.cat([all_ys, y]);\n",
    "\n",
    "            # Back Propagation and Updating weights\n",
    "            loss.backward()\n",
    "            nn_optimizer.step()\n",
    "\n",
    "            running_loss = running_loss + loss.item();\n",
    "\n",
    "            if ite % print_every_step == print_every_step-1:\n",
    "                \n",
    "                # Compute Sigmoid Activation and Prediction Probabilities\n",
    "                preds_sigmoid = torch.sigmoid(all_preds).cpu().detach().numpy();\n",
    "                \n",
    "                # Compute Predictions over the Sigmoid base line\n",
    "                all_preds = (preds_sigmoid > 0.5).astype(int);\n",
    "\n",
    "                # Compute Metrics\n",
    "                all_ys = all_ys.detach().cpu().numpy();\n",
    "\n",
    "                f_score = f1_score(all_ys, all_preds);\n",
    "                precision = precision_score(all_ys, all_preds);\n",
    "                recall = recall_score(all_ys, all_preds);\n",
    "                accuracy = accuracy_score(all_ys, all_preds);\n",
    "\n",
    "                print('\\t[%d %5d %.2f sec] loss: %.3f acc: %.3f prec: %.3f rec: %.3f f1: %.3f'%(epoch+1, ite+1, time.time() - init_time, running_loss / 2000, accuracy, precision, recall, f_score))\n",
    "\n",
    "                all_ys = torch.tensor(data=[]).to(device);\n",
    "                all_preds = torch.tensor(data=[]).to(device);\n",
    "        \n",
    "        print('Epoch %d done in %.2f min'%(epoch+1, (time.time() - epoch_time)/60 ));\n",
    "\n",
    "        if val_loader is not None:\n",
    "            eval(nn_model, nn_criterion, val_loader);\n",
    "        \n",
    "        running_loss = 0.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(nn_model, nn_criterion, data_loader):\n",
    "\n",
    "    # Disable weight updates\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Enable Model Evaluation\n",
    "        nn_model.eval()\n",
    "        running_loss = 0;\n",
    "        \n",
    "        all_ys = torch.tensor(data=[]).to(device);\n",
    "        all_preds = torch.tensor(data=[]).to(device);\n",
    "\n",
    "        init_time = time.time();\n",
    "\n",
    "        for ite, (x, y, l) in enumerate(data_loader):\n",
    "\n",
    "            # Convert tensors to GPU tensors\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            # Forward propagation to compute predictions\n",
    "            preds = nn_model.forward(x, l)\n",
    "\n",
    "            # Compute loss on these predictions\n",
    "            loss = nn_criterion(preds, y)\n",
    "\n",
    "            all_preds = torch.cat([all_preds, preds]);\n",
    "            all_ys = torch.cat([all_ys, y]);\n",
    "\n",
    "            running_loss = running_loss + loss.item();\n",
    "\n",
    "        # Compute Sigmoid activation on the predictions, and derive predictions over the Sigmoid base line\n",
    "        preds_sigmoid = torch.sigmoid(all_preds).cpu().detach().numpy();\n",
    "        all_preds = (preds_sigmoid > 0.5).astype(int);\n",
    "\n",
    "        # Compute metrics\n",
    "        all_ys = all_ys.detach().cpu().numpy();\n",
    "        f_score = f1_score(all_ys, all_preds);\n",
    "\n",
    "        precision = precision_score(all_ys, all_preds);\n",
    "        recall = recall_score(all_ys, all_preds);\n",
    "        accuracy = accuracy_score(all_ys, all_preds);\n",
    "\n",
    "        print('\\tEVAL: [%5d %.2f sec] loss: %.3f acc: %.3f prec: %.3f rec: %.3f f1: %.3f'%(ite+1, time.time() - init_time, running_loss / 2000, accuracy, precision, recall, f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Training on the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with model: \n",
      "Model(\n",
      "  (embedding_layer): Embedding(100001, 100)\n",
      "  (lstm_1): LSTM(100, 64, bidirectional=True)\n",
      "  (fc_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (lstm_2): LSTM(128, 64, bidirectional=True)\n",
      "  (fc_2): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "\t[1   356 0.13 sec] loss: 0.038 acc: 0.938 prec: 0.548 rec: 0.004 f1: 0.008\n",
      "\t[1   712 0.13 sec] loss: 0.069 acc: 0.940 prec: 0.615 rec: 0.104 f1: 0.178\n",
      "\t[1  1068 0.13 sec] loss: 0.098 acc: 0.942 prec: 0.629 rec: 0.180 f1: 0.279\n",
      "\t[1  1424 0.13 sec] loss: 0.125 acc: 0.943 prec: 0.615 rec: 0.207 f1: 0.310\n",
      "\t[1  1780 0.14 sec] loss: 0.152 acc: 0.944 prec: 0.617 rec: 0.231 f1: 0.336\n",
      "\t[1  2136 0.14 sec] loss: 0.179 acc: 0.945 prec: 0.640 rec: 0.255 f1: 0.365\n",
      "\t[1  2492 0.14 sec] loss: 0.205 acc: 0.946 prec: 0.650 rec: 0.277 f1: 0.389\n",
      "\t[1  2848 0.14 sec] loss: 0.231 acc: 0.946 prec: 0.635 rec: 0.272 f1: 0.381\n",
      "\t[1  3204 0.13 sec] loss: 0.256 acc: 0.947 prec: 0.652 rec: 0.288 f1: 0.399\n",
      "\t[1  3560 0.13 sec] loss: 0.281 acc: 0.947 prec: 0.648 rec: 0.306 f1: 0.416\n",
      "Epoch 1 done in 164.36\n",
      "\t[2   356 0.14 sec] loss: 0.023 acc: 0.950 prec: 0.689 rec: 0.364 f1: 0.476\n",
      "\t[2   712 0.14 sec] loss: 0.046 acc: 0.950 prec: 0.682 rec: 0.375 f1: 0.484\n",
      "\t[2  1068 0.14 sec] loss: 0.068 acc: 0.952 prec: 0.687 rec: 0.397 f1: 0.504\n",
      "\t[2  1424 0.14 sec] loss: 0.090 acc: 0.952 prec: 0.683 rec: 0.404 f1: 0.508\n",
      "\t[2  1780 0.14 sec] loss: 0.112 acc: 0.951 prec: 0.682 rec: 0.406 f1: 0.509\n",
      "\t[2  2136 0.14 sec] loss: 0.134 acc: 0.951 prec: 0.680 rec: 0.435 f1: 0.530\n",
      "\t[2  2492 0.14 sec] loss: 0.156 acc: 0.953 prec: 0.678 rec: 0.436 f1: 0.531\n",
      "\t[2  2848 0.14 sec] loss: 0.177 acc: 0.953 prec: 0.689 rec: 0.458 f1: 0.550\n",
      "\t[2  3204 0.14 sec] loss: 0.198 acc: 0.953 prec: 0.673 rec: 0.443 f1: 0.534\n",
      "\t[2  3560 0.14 sec] loss: 0.219 acc: 0.954 prec: 0.694 rec: 0.462 f1: 0.554\n",
      "Epoch 2 done in 164.47\n",
      "\t[3   356 0.14 sec] loss: 0.020 acc: 0.956 prec: 0.709 rec: 0.509 f1: 0.593\n",
      "\t[3   712 0.14 sec] loss: 0.039 acc: 0.956 prec: 0.708 rec: 0.513 f1: 0.595\n",
      "\t[3  1068 0.14 sec] loss: 0.059 acc: 0.955 prec: 0.697 rec: 0.500 f1: 0.582\n",
      "\t[3  1424 0.14 sec] loss: 0.079 acc: 0.956 prec: 0.700 rec: 0.498 f1: 0.582\n",
      "\t[3  1780 0.14 sec] loss: 0.099 acc: 0.956 prec: 0.705 rec: 0.504 f1: 0.588\n",
      "\t[3  2136 0.14 sec] loss: 0.119 acc: 0.957 prec: 0.706 rec: 0.499 f1: 0.585\n",
      "\t[3  2492 0.14 sec] loss: 0.139 acc: 0.956 prec: 0.700 rec: 0.492 f1: 0.578\n",
      "\t[3  2848 0.14 sec] loss: 0.158 acc: 0.957 prec: 0.707 rec: 0.514 f1: 0.595\n",
      "\t[3  3204 0.14 sec] loss: 0.177 acc: 0.958 prec: 0.704 rec: 0.523 f1: 0.600\n",
      "\t[3  3560 0.14 sec] loss: 0.196 acc: 0.957 prec: 0.709 rec: 0.505 f1: 0.590\n",
      "Epoch 3 done in 164.54\n",
      "\t[4   356 0.14 sec] loss: 0.018 acc: 0.959 prec: 0.722 rec: 0.544 f1: 0.620\n",
      "\t[4   712 0.14 sec] loss: 0.036 acc: 0.958 prec: 0.722 rec: 0.545 f1: 0.621\n",
      "\t[4  1068 0.14 sec] loss: 0.055 acc: 0.958 prec: 0.715 rec: 0.543 f1: 0.618\n",
      "\t[4  1424 0.14 sec] loss: 0.073 acc: 0.959 prec: 0.724 rec: 0.548 f1: 0.624\n",
      "\t[4  1780 0.13 sec] loss: 0.092 acc: 0.958 prec: 0.714 rec: 0.550 f1: 0.621\n",
      "\t[4  2136 0.14 sec] loss: 0.110 acc: 0.960 prec: 0.728 rec: 0.541 f1: 0.620\n",
      "\t[4  2492 0.14 sec] loss: 0.128 acc: 0.959 prec: 0.724 rec: 0.528 f1: 0.610\n",
      "\t[4  2848 0.14 sec] loss: 0.147 acc: 0.958 prec: 0.715 rec: 0.521 f1: 0.603\n",
      "\t[4  3204 0.13 sec] loss: 0.166 acc: 0.958 prec: 0.721 rec: 0.544 f1: 0.621\n",
      "\t[4  3560 0.14 sec] loss: 0.185 acc: 0.958 prec: 0.715 rec: 0.541 f1: 0.616\n",
      "Epoch 4 done in 163.86\n",
      "\t[5   356 0.14 sec] loss: 0.017 acc: 0.962 prec: 0.733 rec: 0.581 f1: 0.648\n",
      "\t[5   712 0.14 sec] loss: 0.034 acc: 0.961 prec: 0.734 rec: 0.568 f1: 0.640\n",
      "\t[5  1068 0.14 sec] loss: 0.052 acc: 0.961 prec: 0.734 rec: 0.566 f1: 0.639\n",
      "\t[5  1424 0.14 sec] loss: 0.070 acc: 0.960 prec: 0.729 rec: 0.578 f1: 0.644\n",
      "\t[5  1780 0.14 sec] loss: 0.088 acc: 0.960 prec: 0.726 rec: 0.565 f1: 0.635\n",
      "\t[5  2136 0.14 sec] loss: 0.106 acc: 0.961 prec: 0.738 rec: 0.580 f1: 0.650\n",
      "\t[5  2492 0.14 sec] loss: 0.123 acc: 0.960 prec: 0.722 rec: 0.564 f1: 0.633\n",
      "\t[5  2848 0.13 sec] loss: 0.141 acc: 0.961 prec: 0.735 rec: 0.567 f1: 0.640\n",
      "\t[5  3204 0.14 sec] loss: 0.159 acc: 0.960 prec: 0.730 rec: 0.561 f1: 0.634\n",
      "\t[5  3560 0.14 sec] loss: 0.177 acc: 0.960 prec: 0.734 rec: 0.562 f1: 0.637\n",
      "Epoch 5 done in 164.38\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEVAL: [  764 16.99 sec] loss: 0.046 acc: 0.953 prec: 0.617 rec: 0.480 f1: 0.540\n"
     ]
    }
   ],
   "source": [
    "eval(model, criterion, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best training F1 score is **0.637** over 5 epochs and the evaluation F1 score is **0.540**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
