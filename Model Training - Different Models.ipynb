{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training - Different Models\n",
    "\n",
    "In this notebook, I will experiment with different types of models, and see if they show improvement over the basic model.\n",
    "\n",
    "First, let's bring in all the code from the previous notebook as the starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "\n",
    "import torch;\n",
    "from torch import nn;\n",
    "from torch.utils.data import Dataset, DataLoader;\n",
    "import torch.nn.functional as F;\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score;\n",
    "\n",
    "import math;\n",
    "from numpy import save, load;\n",
    "import keras_sequence_preprocessing as seq_preprocessing;\n",
    "import keras_text_preprocessing as text_preprocessing;\n",
    "\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import time;\n",
    "\n",
    "from PyTorchTools import EarlyStopping;\n",
    "\n",
    "quora_train_text = pd.read_csv('data/augmented_quora_text.txt');\n",
    "quora_train_text = quora_train_text.dropna()\n",
    "\n",
    "embed_size = 300;\n",
    "\n",
    "# FASTTEXT Embeddings\n",
    "\n",
    "embeddings_dict = {};\n",
    "with open('../Embeddings/crawl-%dd-2M.vec'%(embed_size), 'rb') as f:\n",
    "    for line in f:\n",
    "        splits = line.split();\n",
    "        word = splits[0];\n",
    "        vec = np.asarray(splits[1:], dtype='float32')\n",
    "        \n",
    "        embeddings_dict[word.decode()] = vec;\n",
    "        \n",
    "word_index = {};\n",
    "\n",
    "token_num = 0;\n",
    "for row in quora_train_text[['cleaned_text', 'target']].iterrows():\n",
    "    text, label = row[1]\n",
    "    \n",
    "    tokens = [token for token in text.split(' ')];\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in word_index:\n",
    "            word_index[token] = token_num;\n",
    "            token_num = token_num + 1;\n",
    "\n",
    "MAX_WORDS = 200000\n",
    "MAX_LEN = 70\n",
    "\n",
    "def encode_sentences(sentence, word_index=word_index, max_words=MAX_WORDS):\n",
    "    output = [];\n",
    "    for token in sentence.split(' '):\n",
    "        if (token in word_index) and (word_index[token] < max_words):\n",
    "            output.append(word_index[token]);\n",
    "    return output;\n",
    "\n",
    "encoded_sentences = [encode_sentences(sent) for sent in quora_train_text['cleaned_text']]\n",
    "encoded_lengths = [len(x) for x in encoded_sentences]\n",
    "padded_sequences = seq_preprocessing.pad_sequences(encoded_sentences, maxlen=MAX_LEN, padding='post', truncating='post');\n",
    "\n",
    "val_split = int(0.85 * len(quora_train_text));\n",
    "\n",
    "train_ds = padded_sequences[:val_split];\n",
    "val_ds = padded_sequences[val_split:];\n",
    "\n",
    "train_y = quora_train_text.iloc[:val_split]['target'].values;\n",
    "val_y = quora_train_text.iloc[val_split:]['target'].values;\n",
    "\n",
    "train_lens = encoded_lengths[:val_split];\n",
    "val_lens = encoded_lengths[val_split:];\n",
    "\n",
    "len(train_ds), len(val_ds)\n",
    "\n",
    "vocab_size = min(MAX_WORDS, len(word_index))+1;\n",
    "embeddings_matrix = np.zeros((vocab_size, embed_size));\n",
    "\n",
    "for word, posit in word_index.items():\n",
    "    if posit >= vocab_size:\n",
    "        break;\n",
    "        \n",
    "    vec = embeddings_dict.get(word);\n",
    "    if vec is None:\n",
    "        vec = np.random.sample(embed_size);\n",
    "        embeddings_dict[word] = vec;\n",
    "    \n",
    "    embeddings_matrix[posit] = vec;\n",
    "    \n",
    "class QuoraDataset(Dataset):\n",
    "    def __init__(self, encoded_sentences, labels, lengths):\n",
    "        self.encoded_sentences = encoded_sentences;\n",
    "        self.labels = labels;\n",
    "        self.lengths = lengths;\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_sentences);\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.encoded_sentences[index, :];\n",
    "        x = torch.LongTensor(x);\n",
    "        \n",
    "        y = self.labels[index];\n",
    "        y = torch.Tensor([y]);\n",
    "        \n",
    "        length = self.lengths[index];\n",
    "        length = torch.Tensor([length]);\n",
    "        \n",
    "        return x, y, length;\n",
    "    \n",
    "train_dataset = QuoraDataset(train_ds, train_y, train_lens);\n",
    "val_dataset = QuoraDataset(val_ds, val_y, val_lens);\n",
    "\n",
    "batch_size = 512;\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True);\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True);\n",
    "\n",
    "def train(nn_model, nn_optimizer, nn_criterion, data_loader, val_loader = None, num_epochs = 5, print_ratio = 0.1, verbose=True):\n",
    "    \n",
    "    print_every_step = int(print_ratio * len(train_loader));\n",
    "    \n",
    "    if verbose:\n",
    "        print('Training with model: ');\n",
    "        print(nn_model);\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        epoch_time = time.time();    \n",
    "\n",
    "        f1_scores_train = []\n",
    "\n",
    "        # Enable Training for the model\n",
    "        nn_model.train()\n",
    "        running_loss = 0;\n",
    "\n",
    "        all_ys = torch.tensor(data=[]).to(device);\n",
    "        all_preds = torch.tensor(data=[]).to(device);\n",
    "\n",
    "        for ite, (x, y, l) in enumerate(data_loader):\n",
    "            init_time = time.time();\n",
    "\n",
    "            # Convert our tensors to GPU tensors\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            nn_optimizer.zero_grad()\n",
    "\n",
    "            # Forward Propagation and compute predictions\n",
    "            preds = nn_model.forward(x, l)\n",
    "\n",
    "            # Compute loss against actual values\n",
    "            loss = nn_criterion(preds, y)\n",
    "\n",
    "            # Add predictions and actuals into larger list for scoring\n",
    "            all_preds = torch.cat([all_preds, preds]);\n",
    "            all_ys = torch.cat([all_ys, y]);\n",
    "\n",
    "            # Back Propagation and Updating weights\n",
    "            loss.backward()\n",
    "            nn_optimizer.step()\n",
    "\n",
    "            running_loss = running_loss + loss.item();\n",
    "\n",
    "            if ite % print_every_step == print_every_step-1:\n",
    "                \n",
    "                # Compute Sigmoid Activation and Prediction Probabilities\n",
    "                preds_sigmoid = torch.sigmoid(all_preds).cpu().detach().numpy();\n",
    "                \n",
    "                # Compute Predictions over the Sigmoid base line\n",
    "                all_preds = (preds_sigmoid > 0.5).astype(int);\n",
    "\n",
    "                # Compute Metrics\n",
    "                all_ys = all_ys.detach().cpu().numpy();\n",
    "\n",
    "                f_score = f1_score(all_ys, all_preds);\n",
    "                precision = precision_score(all_ys, all_preds);\n",
    "                recall = recall_score(all_ys, all_preds);\n",
    "                accuracy = accuracy_score(all_ys, all_preds);\n",
    "\n",
    "                print('\\t[%d %5d %.2f sec] loss: %.3f acc: %.3f prec: %.3f rec: %.3f f1: %.3f'%(epoch+1, ite+1, time.time() - init_time, running_loss / 2000, accuracy, precision, recall, f_score))\n",
    "\n",
    "                all_ys = torch.tensor(data=[]).to(device);\n",
    "                all_preds = torch.tensor(data=[]).to(device);\n",
    "        \n",
    "        print('Epoch %d done in %.2f min'%(epoch+1, (time.time() - epoch_time)/60 ));\n",
    "\n",
    "        if val_loader is not None:\n",
    "            eval(nn_model, nn_criterion, val_loader);\n",
    "        \n",
    "        running_loss = 0.0;\n",
    "        \n",
    "def eval(nn_model, nn_criterion, data_loader):\n",
    "\n",
    "    # Disable weight updates\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Enable Model Evaluation\n",
    "        nn_model.eval()\n",
    "        running_loss = 0;\n",
    "        \n",
    "        all_ys = torch.tensor(data=[]).to(device);\n",
    "        all_preds = torch.tensor(data=[]).to(device);\n",
    "\n",
    "        init_time = time.time();\n",
    "\n",
    "        for ite, (x, y, l) in enumerate(data_loader):\n",
    "\n",
    "            # Convert tensors to GPU tensors\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            # Forward propagation to compute predictions\n",
    "            preds = nn_model.forward(x, l)\n",
    "\n",
    "            # Compute loss on these predictions\n",
    "            loss = nn_criterion(preds, y)\n",
    "\n",
    "            all_preds = torch.cat([all_preds, preds]);\n",
    "            all_ys = torch.cat([all_ys, y]);\n",
    "\n",
    "            running_loss = running_loss + loss.item();\n",
    "\n",
    "        # Compute Sigmoid activation on the predictions, and derive predictions over the Sigmoid base line\n",
    "        preds_sigmoid = torch.sigmoid(all_preds).cpu().detach().numpy();\n",
    "        all_preds = (preds_sigmoid > 0.5).astype(int);\n",
    "\n",
    "        # Compute metrics\n",
    "        all_ys = all_ys.detach().cpu().numpy();\n",
    "        f_score = f1_score(all_ys, all_preds);\n",
    "\n",
    "        precision = precision_score(all_ys, all_preds);\n",
    "        recall = recall_score(all_ys, all_preds);\n",
    "        accuracy = accuracy_score(all_ys, all_preds);\n",
    "\n",
    "        print('\\tEVAL: [%5d %.2f sec] loss: %.3f acc: %.3f prec: %.3f rec: %.3f f1: %.3f'%(ite+1, time.time() - init_time, running_loss / 2000, accuracy, precision, recall, f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the Notebook \"Model Training - Basic Model\" for comments and documentation on the starter code.\n",
    "\n",
    "## Model Training with 128 Hidden Units in the first LSTM Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with model: \n",
      "Model(\n",
      "  (embedding_layer): Embedding(100001, 300)\n",
      "  (lstm_1): LSTM(300, 128, bidirectional=True)\n",
      "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (lstm_2): LSTM(256, 128, bidirectional=True)\n",
      "  (fc_2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "\t[1   356 0.16 sec] loss: 0.037 acc: 0.938 prec: 0.540 rec: 0.013 f1: 0.025\n",
      "\t[1   712 0.16 sec] loss: 0.063 acc: 0.945 prec: 0.634 rec: 0.290 f1: 0.398\n",
      "\t[1  1068 0.16 sec] loss: 0.087 acc: 0.948 prec: 0.631 rec: 0.349 f1: 0.449\n",
      "\t[1  1424 0.16 sec] loss: 0.111 acc: 0.950 prec: 0.659 rec: 0.382 f1: 0.484\n",
      "\t[1  1780 0.16 sec] loss: 0.134 acc: 0.950 prec: 0.657 rec: 0.398 f1: 0.495\n",
      "\t[1  2136 0.17 sec] loss: 0.156 acc: 0.951 prec: 0.674 rec: 0.428 f1: 0.524\n",
      "\t[1  2492 0.16 sec] loss: 0.178 acc: 0.951 prec: 0.669 rec: 0.422 f1: 0.517\n",
      "\t[1  2848 0.16 sec] loss: 0.199 acc: 0.953 prec: 0.672 rec: 0.419 f1: 0.516\n",
      "\t[1  3204 0.16 sec] loss: 0.221 acc: 0.952 prec: 0.682 rec: 0.435 f1: 0.531\n",
      "\t[1  3560 0.16 sec] loss: 0.243 acc: 0.952 prec: 0.682 rec: 0.452 f1: 0.543\n",
      "Epoch 1 done in 4.19 min\n",
      "\t[2   356 0.16 sec] loss: 0.020 acc: 0.956 prec: 0.693 rec: 0.467 f1: 0.558\n",
      "\t[2   712 0.16 sec] loss: 0.040 acc: 0.954 prec: 0.692 rec: 0.465 f1: 0.556\n",
      "\t[2  1068 0.16 sec] loss: 0.061 acc: 0.955 prec: 0.701 rec: 0.484 f1: 0.572\n",
      "\t[2  1424 0.16 sec] loss: 0.081 acc: 0.955 prec: 0.702 rec: 0.482 f1: 0.572\n",
      "\t[2  1780 0.16 sec] loss: 0.101 acc: 0.955 prec: 0.703 rec: 0.491 f1: 0.578\n",
      "\t[2  2136 0.16 sec] loss: 0.121 acc: 0.956 prec: 0.700 rec: 0.488 f1: 0.575\n",
      "\t[2  2492 0.16 sec] loss: 0.141 acc: 0.956 prec: 0.705 rec: 0.498 f1: 0.584\n",
      "\t[2  2848 0.16 sec] loss: 0.161 acc: 0.956 prec: 0.702 rec: 0.488 f1: 0.576\n",
      "\t[2  3204 0.16 sec] loss: 0.181 acc: 0.956 prec: 0.703 rec: 0.496 f1: 0.582\n",
      "\t[2  3560 0.16 sec] loss: 0.201 acc: 0.955 prec: 0.702 rec: 0.494 f1: 0.580\n",
      "Epoch 2 done in 4.21 min\n",
      "\t[3   356 0.17 sec] loss: 0.019 acc: 0.958 prec: 0.722 rec: 0.548 f1: 0.623\n",
      "\t[3   712 0.16 sec] loss: 0.037 acc: 0.958 prec: 0.715 rec: 0.528 f1: 0.607\n",
      "\t[3  1068 0.16 sec] loss: 0.056 acc: 0.959 prec: 0.718 rec: 0.526 f1: 0.607\n",
      "\t[3  1424 0.16 sec] loss: 0.075 acc: 0.958 prec: 0.713 rec: 0.526 f1: 0.605\n",
      "\t[3  1780 0.17 sec] loss: 0.094 acc: 0.958 prec: 0.715 rec: 0.536 f1: 0.613\n",
      "\t[3  2136 0.16 sec] loss: 0.113 acc: 0.957 prec: 0.712 rec: 0.531 f1: 0.608\n",
      "\t[3  2492 0.16 sec] loss: 0.132 acc: 0.958 prec: 0.710 rec: 0.518 f1: 0.599\n",
      "\t[3  2848 0.16 sec] loss: 0.151 acc: 0.957 prec: 0.719 rec: 0.525 f1: 0.607\n",
      "\t[3  3204 0.16 sec] loss: 0.170 acc: 0.958 prec: 0.709 rec: 0.527 f1: 0.604\n",
      "\t[3  3560 0.17 sec] loss: 0.189 acc: 0.957 prec: 0.705 rec: 0.517 f1: 0.597\n",
      "Epoch 3 done in 4.20 min\n",
      "\t[4   356 0.16 sec] loss: 0.018 acc: 0.961 prec: 0.725 rec: 0.555 f1: 0.628\n",
      "\t[4   712 0.16 sec] loss: 0.036 acc: 0.960 prec: 0.730 rec: 0.561 f1: 0.634\n",
      "\t[4  1068 0.16 sec] loss: 0.054 acc: 0.959 prec: 0.721 rec: 0.545 f1: 0.621\n",
      "\t[4  1424 0.17 sec] loss: 0.072 acc: 0.960 prec: 0.719 rec: 0.556 f1: 0.627\n",
      "\t[4  1780 0.16 sec] loss: 0.090 acc: 0.959 prec: 0.720 rec: 0.561 f1: 0.630\n",
      "\t[4  2136 0.17 sec] loss: 0.109 acc: 0.958 prec: 0.720 rec: 0.540 f1: 0.617\n",
      "\t[4  2492 0.16 sec] loss: 0.128 acc: 0.958 prec: 0.724 rec: 0.542 f1: 0.620\n",
      "\t[4  2848 0.16 sec] loss: 0.146 acc: 0.959 prec: 0.728 rec: 0.549 f1: 0.626\n",
      "\t[4  3204 0.16 sec] loss: 0.164 acc: 0.959 prec: 0.721 rec: 0.552 f1: 0.625\n",
      "\t[4  3560 0.16 sec] loss: 0.182 acc: 0.959 prec: 0.717 rec: 0.537 f1: 0.615\n",
      "Epoch 4 done in 4.22 min\n",
      "\t[5   356 0.16 sec] loss: 0.018 acc: 0.961 prec: 0.733 rec: 0.571 f1: 0.642\n",
      "\t[5   712 0.16 sec] loss: 0.035 acc: 0.961 prec: 0.732 rec: 0.567 f1: 0.639\n",
      "\t[5  1068 0.16 sec] loss: 0.052 acc: 0.961 prec: 0.734 rec: 0.574 f1: 0.645\n",
      "\t[5  1424 0.16 sec] loss: 0.070 acc: 0.960 prec: 0.725 rec: 0.571 f1: 0.639\n",
      "\t[5  1780 0.16 sec] loss: 0.089 acc: 0.959 prec: 0.726 rec: 0.566 f1: 0.636\n",
      "\t[5  2136 0.16 sec] loss: 0.107 acc: 0.960 prec: 0.726 rec: 0.558 f1: 0.631\n",
      "\t[5  2492 0.16 sec] loss: 0.124 acc: 0.960 prec: 0.724 rec: 0.556 f1: 0.629\n",
      "\t[5  2848 0.17 sec] loss: 0.142 acc: 0.959 prec: 0.730 rec: 0.571 f1: 0.641\n",
      "\t[5  3204 0.16 sec] loss: 0.160 acc: 0.960 prec: 0.722 rec: 0.558 f1: 0.630\n",
      "\t[5  3560 0.16 sec] loss: 0.178 acc: 0.959 prec: 0.725 rec: 0.549 f1: 0.625\n",
      "Epoch 5 done in 4.21 min\n"
     ]
    }
   ],
   "source": [
    "model = Model(embeddings_tensor, 128);\n",
    "model = model.to(device);\n",
    "\n",
    "train(model, optimizer, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEVAL: [  764 18.49 sec] loss: 0.036 acc: 0.966 prec: 0.634 rec: 0.512 f1: 0.567\n"
     ]
    }
   ],
   "source": [
    "eval(model, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\tEVAL: [  764 18.49 sec] loss: 0.046 acc: 0.953 prec: 0.634 rec: 0.512 f1: 0.567')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With 128 Hidden Units in first LSTM Layer: F1 score over 5 epochs:\n",
    "\n",
    "The model shows slight improvement over a model with 64 hidden units.\n",
    "\n",
    "##### Training: 0.625\n",
    "##### Validation: 0.567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with model: \n",
      "Model(\n",
      "  (embedding_layer): Embedding(100001, 300)\n",
      "  (lstm_1): LSTM(300, 128, bidirectional=True)\n",
      "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (lstm_2): LSTM(256, 128, bidirectional=True)\n",
      "  (fc_2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "\t[1   356 0.16 sec] loss: 0.017 acc: 0.962 prec: 0.732 rec: 0.575 f1: 0.644\n",
      "\t[1   712 0.16 sec] loss: 0.034 acc: 0.961 prec: 0.728 rec: 0.569 f1: 0.639\n",
      "\t[1  1068 0.16 sec] loss: 0.052 acc: 0.961 prec: 0.734 rec: 0.585 f1: 0.651\n",
      "\t[1  1424 0.16 sec] loss: 0.069 acc: 0.960 prec: 0.729 rec: 0.570 f1: 0.640\n",
      "\t[1  1780 0.16 sec] loss: 0.087 acc: 0.961 prec: 0.729 rec: 0.579 f1: 0.646\n",
      "\t[1  2136 0.16 sec] loss: 0.104 acc: 0.961 prec: 0.732 rec: 0.584 f1: 0.650\n",
      "\t[1  2492 0.16 sec] loss: 0.122 acc: 0.961 prec: 0.735 rec: 0.576 f1: 0.646\n",
      "\t[1  2848 0.16 sec] loss: 0.139 acc: 0.961 prec: 0.737 rec: 0.590 f1: 0.656\n",
      "\t[1  3204 0.16 sec] loss: 0.157 acc: 0.960 prec: 0.726 rec: 0.574 f1: 0.641\n",
      "\t[1  3560 0.16 sec] loss: 0.175 acc: 0.960 prec: 0.727 rec: 0.571 f1: 0.640\n",
      "Epoch 1 done in 4.20 min\n",
      "\t[2   356 0.16 sec] loss: 0.017 acc: 0.962 prec: 0.742 rec: 0.605 f1: 0.667\n",
      "\t[2   712 0.16 sec] loss: 0.034 acc: 0.961 prec: 0.744 rec: 0.603 f1: 0.666\n",
      "\t[2  1068 0.16 sec] loss: 0.051 acc: 0.961 prec: 0.732 rec: 0.584 f1: 0.650\n",
      "\t[2  1424 0.16 sec] loss: 0.068 acc: 0.962 prec: 0.742 rec: 0.587 f1: 0.655\n",
      "\t[2  1780 0.16 sec] loss: 0.085 acc: 0.963 prec: 0.746 rec: 0.599 f1: 0.665\n",
      "\t[2  2136 0.16 sec] loss: 0.102 acc: 0.962 prec: 0.735 rec: 0.585 f1: 0.651\n",
      "\t[2  2492 0.17 sec] loss: 0.119 acc: 0.961 prec: 0.734 rec: 0.592 f1: 0.655\n",
      "\t[2  2848 0.16 sec] loss: 0.137 acc: 0.961 prec: 0.735 rec: 0.574 f1: 0.644\n",
      "\t[2  3204 0.16 sec] loss: 0.154 acc: 0.961 prec: 0.735 rec: 0.572 f1: 0.644\n",
      "\t[2  3560 0.16 sec] loss: 0.171 acc: 0.962 prec: 0.739 rec: 0.586 f1: 0.654\n",
      "Epoch 2 done in 4.21 min\n",
      "\t[3   356 0.16 sec] loss: 0.017 acc: 0.962 prec: 0.741 rec: 0.592 f1: 0.658\n",
      "\t[3   712 0.16 sec] loss: 0.034 acc: 0.962 prec: 0.742 rec: 0.598 f1: 0.662\n",
      "\t[3  1068 0.17 sec] loss: 0.050 acc: 0.963 prec: 0.749 rec: 0.605 f1: 0.669\n",
      "\t[3  1424 0.16 sec] loss: 0.067 acc: 0.961 prec: 0.739 rec: 0.582 f1: 0.651\n",
      "\t[3  1780 0.16 sec] loss: 0.084 acc: 0.962 prec: 0.749 rec: 0.599 f1: 0.666\n",
      "\t[3  2136 0.16 sec] loss: 0.101 acc: 0.961 prec: 0.736 rec: 0.590 f1: 0.655\n",
      "\t[3  2492 0.16 sec] loss: 0.118 acc: 0.962 prec: 0.740 rec: 0.598 f1: 0.661\n",
      "\t[3  2848 0.17 sec] loss: 0.135 acc: 0.963 prec: 0.741 rec: 0.603 f1: 0.665\n",
      "\t[3  3204 0.16 sec] loss: 0.152 acc: 0.963 prec: 0.741 rec: 0.603 f1: 0.665\n",
      "\t[3  3560 0.16 sec] loss: 0.169 acc: 0.962 prec: 0.739 rec: 0.593 f1: 0.658\n",
      "Epoch 3 done in 4.20 min\n",
      "\t[4   356 0.17 sec] loss: 0.016 acc: 0.964 prec: 0.741 rec: 0.607 f1: 0.667\n",
      "\t[4   712 0.16 sec] loss: 0.033 acc: 0.963 prec: 0.749 rec: 0.607 f1: 0.670\n",
      "\t[4  1068 0.16 sec] loss: 0.050 acc: 0.963 prec: 0.751 rec: 0.619 f1: 0.678\n",
      "\t[4  1424 0.16 sec] loss: 0.066 acc: 0.964 prec: 0.757 rec: 0.614 f1: 0.678\n",
      "\t[4  1780 0.16 sec] loss: 0.083 acc: 0.963 prec: 0.745 rec: 0.604 f1: 0.667\n",
      "\t[4  2136 0.16 sec] loss: 0.099 acc: 0.963 prec: 0.753 rec: 0.601 f1: 0.669\n",
      "\t[4  2492 0.17 sec] loss: 0.116 acc: 0.963 prec: 0.751 rec: 0.603 f1: 0.669\n",
      "\t[4  2848 0.16 sec] loss: 0.133 acc: 0.962 prec: 0.736 rec: 0.596 f1: 0.658\n",
      "\t[4  3204 0.16 sec] loss: 0.150 acc: 0.962 prec: 0.738 rec: 0.590 f1: 0.656\n",
      "\t[4  3560 0.16 sec] loss: 0.166 acc: 0.963 prec: 0.748 rec: 0.611 f1: 0.672\n",
      "Epoch 4 done in 4.22 min\n",
      "\t[5   356 0.16 sec] loss: 0.016 acc: 0.964 prec: 0.761 rec: 0.622 f1: 0.684\n",
      "\t[5   712 0.16 sec] loss: 0.032 acc: 0.964 prec: 0.754 rec: 0.614 f1: 0.677\n",
      "\t[5  1068 0.16 sec] loss: 0.048 acc: 0.963 prec: 0.757 rec: 0.617 f1: 0.680\n",
      "\t[5  1424 0.16 sec] loss: 0.065 acc: 0.964 prec: 0.751 rec: 0.612 f1: 0.675\n",
      "\t[5  1780 0.17 sec] loss: 0.081 acc: 0.964 prec: 0.756 rec: 0.624 f1: 0.684\n",
      "\t[5  2136 0.16 sec] loss: 0.097 acc: 0.963 prec: 0.749 rec: 0.608 f1: 0.672\n",
      "\t[5  2492 0.16 sec] loss: 0.114 acc: 0.963 prec: 0.751 rec: 0.601 f1: 0.668\n",
      "\t[5  2848 0.16 sec] loss: 0.130 acc: 0.964 prec: 0.749 rec: 0.603 f1: 0.668\n",
      "\t[5  3204 0.16 sec] loss: 0.147 acc: 0.963 prec: 0.743 rec: 0.595 f1: 0.661\n",
      "\t[5  3560 0.16 sec] loss: 0.163 acc: 0.963 prec: 0.742 rec: 0.597 f1: 0.661\n",
      "Epoch 5 done in 4.20 min\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEVAL: [  764 18.01 sec] loss: 0.030 acc: 0.983 prec: 0.615 rec: 0.510 f1: 0.558\n"
     ]
    }
   ],
   "source": [
    "eval(model, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With 128 Hidden Units in first LSTM Layer: F1 score over 10 epochs:\n",
    "\n",
    "The model starts overfitting after additional epochs, with good improvement in training, but a small dip in validation.\n",
    "\n",
    "##### Training: 0.661\n",
    "##### Validation: 0.558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffscore(prec, recall):\n",
    "    return (2 * prec * recall) / (prec + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5576"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffscore(0.615, 0.510)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "Next, we will add an Attention layer, which will allow the model to learn deeper context between words\n",
    "\n",
    "I borrowed implementation of an Attention Layer from the following Gist:\n",
    "https://gist.github.com/thomwolf/dec72992ea6817290273d42f6b95c04c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, batch_first=False):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self.att_weights = nn.Parameter(torch.Tensor(1, hidden_size), requires_grad=True)\n",
    "\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.att_weights:\n",
    "            nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def get_mask(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        if self.batch_first:\n",
    "            batch_size, max_len = inputs.size()[:2]\n",
    "        else:\n",
    "            max_len, batch_size = inputs.size()[:2]\n",
    "            \n",
    "        # apply attention layer\n",
    "        weights = torch.bmm(inputs,\n",
    "                            self.att_weights  # (1, hidden_size)\n",
    "                            .permute(1, 0)  # (hidden_size, 1)\n",
    "                            .unsqueeze(0)  # (1, hidden_size, 1)\n",
    "                            .repeat(batch_size, 1, 1) # (batch_size, hidden_size, 1)\n",
    "                            )\n",
    "    \n",
    "        attentions = torch.softmax(F.relu(weights.squeeze()), dim=-1)\n",
    "\n",
    "        # create mask based on the sentence lengths\n",
    "        mask = torch.ones(attentions.size(), requires_grad=True).cuda()\n",
    "        \n",
    "        lengths = lengths.to(dtype=torch.long, device=device)\n",
    "        for i, l in enumerate(lengths):  # skip the first sentence\n",
    "            if l < max_len:\n",
    "                mask[i, l:] = 0\n",
    "\n",
    "        # apply mask and renormalize attention scores (weights)\n",
    "        masked = attentions * mask\n",
    "        _sums = masked.sum(-1).unsqueeze(-1)  # sums per row\n",
    "        \n",
    "        attentions = masked.div(_sums)\n",
    "\n",
    "        # apply attention weights\n",
    "        weighted = torch.mul(inputs, attentions.unsqueeze(-1).expand_as(inputs))\n",
    "\n",
    "        # get the final fixed vector representations of the sentences\n",
    "        representations = weighted.sum(1).squeeze()\n",
    "\n",
    "        return representations, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_unit = 64):\n",
    "        super(AttentionModel, self).__init__();\n",
    "        vocab_size = embeddings_tensor.shape[0];\n",
    "        embedding_dim = embeddings_tensor.shape[1];\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim);\n",
    "        self.embedding_layer.weight = nn.Parameter(embeddings_tensor);\n",
    "        self.embedding_layer.weight.requires_grad = True;\n",
    "        \n",
    "        self.lstm_1 = nn.LSTM(embedding_dim, hidden_unit, bidirectional=True);\n",
    "        \n",
    "        self.attn_1 = SelfAttention(hidden_unit*2, batch_first=True);\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hidden_unit*2, hidden_unit*2);\n",
    "        \n",
    "        self.fc_2 = nn.Linear(hidden_unit * 2, 1);\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        out = self.embedding_layer(x);\n",
    "        \n",
    "        out, _ = self.lstm_1(out);\n",
    "        \n",
    "        out, _ = self.attn_1(out, l);\n",
    "        \n",
    "        out = self.fc_1(out);\n",
    "        \n",
    "        out = torch.relu(out);\n",
    "        \n",
    "        out = self.fc_2(out);\n",
    "        return out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionModel(\n",
       "  (embedding_layer): Embedding(200001, 300)\n",
       "  (lstm_1): LSTM(300, 128, bidirectional=True)\n",
       "  (attn_1): SelfAttention()\n",
       "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc_2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_model = AttentionModel(embeddings_tensor, 128)\n",
    "attn_model = attn_model.to(device);\n",
    "attn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss();\n",
    "optimizer = torch.optim.Adam(lr=0.003, params = attn_model.parameters());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also make some changes to the model to accomodate the LSTM layer. We have a single LSTM Layer, that feeds into the Attention Layer, following by two Fully Connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with model: \n",
      "AttentionModel(\n",
      "  (embedding_layer): Embedding(200001, 300)\n",
      "  (lstm_1): LSTM(300, 128, bidirectional=True)\n",
      "  (attn_1): SelfAttention()\n",
      "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc_2): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "\t[1   356 0.37 sec] loss: 0.026 acc: 0.946 prec: 0.631 rec: 0.326 f1: 0.430\n",
      "\t[1   712 0.40 sec] loss: 0.047 acc: 0.952 prec: 0.660 rec: 0.467 f1: 0.547\n",
      "\t[1  1068 0.37 sec] loss: 0.068 acc: 0.952 prec: 0.662 rec: 0.481 f1: 0.557\n",
      "\t[1  1424 0.39 sec] loss: 0.089 acc: 0.955 prec: 0.684 rec: 0.521 f1: 0.592\n",
      "\t[1  1780 0.36 sec] loss: 0.109 acc: 0.954 prec: 0.683 rec: 0.496 f1: 0.575\n",
      "\t[1  2136 0.36 sec] loss: 0.129 acc: 0.956 prec: 0.685 rec: 0.514 f1: 0.587\n",
      "\t[1  2492 0.37 sec] loss: 0.149 acc: 0.954 prec: 0.681 rec: 0.499 f1: 0.576\n",
      "\t[1  2848 0.37 sec] loss: 0.169 acc: 0.956 prec: 0.682 rec: 0.513 f1: 0.585\n",
      "\t[1  3204 0.36 sec] loss: 0.188 acc: 0.957 prec: 0.696 rec: 0.530 f1: 0.602\n",
      "\t[1  3560 0.36 sec] loss: 0.207 acc: 0.956 prec: 0.688 rec: 0.526 f1: 0.596\n",
      "Epoch 1 done in 13.47 min\n",
      "\t[2   356 0.37 sec] loss: 0.016 acc: 0.963 prec: 0.745 rec: 0.624 f1: 0.679\n",
      "\t[2   712 0.37 sec] loss: 0.032 acc: 0.964 prec: 0.744 rec: 0.631 f1: 0.683\n",
      "\t[2  1068 0.36 sec] loss: 0.049 acc: 0.963 prec: 0.743 rec: 0.628 f1: 0.680\n",
      "\t[2  1424 0.36 sec] loss: 0.065 acc: 0.964 prec: 0.747 rec: 0.623 f1: 0.679\n",
      "\t[2  2492 0.37 sec] loss: 0.114 acc: 0.962 prec: 0.734 rec: 0.605 f1: 0.663\n",
      "\t[2  2848 0.36 sec] loss: 0.130 acc: 0.963 prec: 0.740 rec: 0.610 f1: 0.669\n",
      "\t[2  3204 0.36 sec] loss: 0.147 acc: 0.963 prec: 0.739 rec: 0.616 f1: 0.672\n",
      "\t[2  3560 0.37 sec] loss: 0.163 acc: 0.963 prec: 0.735 rec: 0.613 f1: 0.669\n",
      "Epoch 2 done in 13.34 min\n",
      "\t[3   356 0.36 sec] loss: 0.013 acc: 0.971 prec: 0.794 rec: 0.707 f1: 0.748\n",
      "\t[3   712 0.36 sec] loss: 0.026 acc: 0.969 prec: 0.784 rec: 0.704 f1: 0.742\n",
      "\t[3  1068 0.38 sec] loss: 0.040 acc: 0.970 prec: 0.797 rec: 0.697 f1: 0.744\n",
      "\t[3  1424 0.36 sec] loss: 0.054 acc: 0.968 prec: 0.773 rec: 0.677 f1: 0.722\n",
      "\t[3  1780 0.37 sec] loss: 0.067 acc: 0.970 prec: 0.788 rec: 0.685 f1: 0.733\n",
      "\t[3  2136 0.36 sec] loss: 0.082 acc: 0.968 prec: 0.782 rec: 0.681 f1: 0.728\n",
      "\t[3  2492 0.37 sec] loss: 0.096 acc: 0.969 prec: 0.778 rec: 0.678 f1: 0.724\n",
      "\t[3  2848 0.37 sec] loss: 0.110 acc: 0.968 prec: 0.779 rec: 0.676 f1: 0.724\n",
      "\t[3  3204 0.36 sec] loss: 0.124 acc: 0.968 prec: 0.778 rec: 0.672 f1: 0.721\n",
      "\t[3  3560 0.36 sec] loss: 0.138 acc: 0.969 prec: 0.783 rec: 0.679 f1: 0.727\n",
      "Epoch 3 done in 13.32 min\n",
      "\t[4   356 0.36 sec] loss: 0.011 acc: 0.974 prec: 0.823 rec: 0.734 f1: 0.776\n",
      "\t[4   712 0.37 sec] loss: 0.022 acc: 0.975 prec: 0.824 rec: 0.750 f1: 0.785\n",
      "\t[4  1068 0.37 sec] loss: 0.034 acc: 0.974 prec: 0.819 rec: 0.735 f1: 0.774\n",
      "\t[4  1424 0.37 sec] loss: 0.046 acc: 0.972 prec: 0.811 rec: 0.726 f1: 0.766\n",
      "\t[4  1780 0.37 sec] loss: 0.059 acc: 0.973 prec: 0.811 rec: 0.727 f1: 0.767\n",
      "\t[4  2136 0.37 sec] loss: 0.071 acc: 0.972 prec: 0.804 rec: 0.723 f1: 0.762\n",
      "\t[4  2492 0.37 sec] loss: 0.084 acc: 0.972 prec: 0.806 rec: 0.720 f1: 0.761\n",
      "\t[4  2848 0.37 sec] loss: 0.096 acc: 0.972 prec: 0.808 rec: 0.724 f1: 0.764\n",
      "\t[4  3204 0.37 sec] loss: 0.109 acc: 0.972 prec: 0.802 rec: 0.706 f1: 0.751\n",
      "\t[4  3560 0.37 sec] loss: 0.122 acc: 0.970 prec: 0.790 rec: 0.704 f1: 0.744\n",
      "Epoch 4 done in 13.49 min\n",
      "\t[5   356 0.37 sec] loss: 0.010 acc: 0.977 prec: 0.840 rec: 0.764 f1: 0.800\n",
      "\t[5   712 0.37 sec] loss: 0.020 acc: 0.976 prec: 0.833 rec: 0.770 f1: 0.800\n",
      "\t[5  1068 0.37 sec] loss: 0.031 acc: 0.976 prec: 0.831 rec: 0.763 f1: 0.796\n",
      "\t[5  1424 0.37 sec] loss: 0.042 acc: 0.974 prec: 0.823 rec: 0.742 f1: 0.780\n",
      "\t[5  1780 0.37 sec] loss: 0.053 acc: 0.974 prec: 0.819 rec: 0.752 f1: 0.784\n",
      "\t[5  2136 0.37 sec] loss: 0.064 acc: 0.974 prec: 0.823 rec: 0.740 f1: 0.779\n",
      "\t[5  2492 0.37 sec] loss: 0.076 acc: 0.974 prec: 0.819 rec: 0.741 f1: 0.778\n",
      "\t[5  2848 0.37 sec] loss: 0.087 acc: 0.974 prec: 0.822 rec: 0.740 f1: 0.779\n",
      "\t[5  3204 0.37 sec] loss: 0.099 acc: 0.973 prec: 0.819 rec: 0.740 f1: 0.778\n",
      "\t[5  3560 0.37 sec] loss: 0.111 acc: 0.973 prec: 0.812 rec: 0.734 f1: 0.771\n",
      "Epoch 5 done in 13.51 min\n"
     ]
    }
   ],
   "source": [
    "train(attn_model, optimizer, criterion, train_loader, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ravis\\anaconda3\\envs\\pysci\\lib\\site-packages\\ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEVAL: [  764 83.75 sec] loss: nan acc: 0.951 prec: 0.610 rec: 0.592 f1: 0.601\n"
     ]
    }
   ],
   "source": [
    "eval(attn_model, criterion, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see a Drastic improvement in the model with a single Attention layer.\n",
    "\n",
    "#### Training F1 score is 0.771\n",
    "#### Validation F1 score is 0.601\n",
    "\n",
    "The improvement in validation is not significant, but still noticable with a jump of 5%.\n",
    "\n",
    "Let's try training on additional Epochs and see if there is any improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with model: \n",
      "AttentionModel(\n",
      "  (embedding_layer): Embedding(200001, 300)\n",
      "  (lstm_1): LSTM(300, 128, bidirectional=True)\n",
      "  (attn_1): SelfAttention()\n",
      "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc_2): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "\t[1   356 0.37 sec] loss: 0.009 acc: 0.978 prec: 0.848 rec: 0.782 f1: 0.814\n",
      "\t[1   712 0.36 sec] loss: 0.019 acc: 0.978 prec: 0.848 rec: 0.774 f1: 0.809\n",
      "\t[1  1068 0.38 sec] loss: 0.029 acc: 0.977 prec: 0.839 rec: 0.782 f1: 0.810\n",
      "\t[1  1424 0.37 sec] loss: 0.039 acc: 0.977 prec: 0.840 rec: 0.769 f1: 0.803\n",
      "\t[1  1780 0.37 sec] loss: 0.049 acc: 0.976 prec: 0.840 rec: 0.777 f1: 0.807\n",
      "\t[1  2136 0.37 sec] loss: 0.060 acc: 0.976 prec: 0.837 rec: 0.761 f1: 0.797\n",
      "\t[1  2492 0.36 sec] loss: 0.071 acc: 0.975 prec: 0.833 rec: 0.756 f1: 0.792\n",
      "\t[1  2848 0.37 sec] loss: 0.082 acc: 0.975 prec: 0.824 rec: 0.751 f1: 0.786\n",
      "\t[1  3204 0.37 sec] loss: 0.093 acc: 0.975 prec: 0.826 rec: 0.747 f1: 0.784\n",
      "\t[1  3560 0.37 sec] loss: 0.104 acc: 0.975 prec: 0.820 rec: 0.759 f1: 0.788\n",
      "Epoch 1 done in 13.42 min\n",
      "\t[2   356 0.37 sec] loss: 0.009 acc: 0.980 prec: 0.866 rec: 0.808 f1: 0.836\n",
      "\t[2   712 0.36 sec] loss: 0.018 acc: 0.979 prec: 0.849 rec: 0.795 f1: 0.821\n",
      "\t[2  1068 0.37 sec] loss: 0.028 acc: 0.978 prec: 0.850 rec: 0.783 f1: 0.815\n",
      "\t[2  1424 0.36 sec] loss: 0.037 acc: 0.978 prec: 0.846 rec: 0.789 f1: 0.816\n",
      "\t[2  1780 0.37 sec] loss: 0.046 acc: 0.978 prec: 0.845 rec: 0.782 f1: 0.812\n",
      "\t[2  2136 0.37 sec] loss: 0.056 acc: 0.978 prec: 0.843 rec: 0.779 f1: 0.810\n",
      "\t[2  2492 0.37 sec] loss: 0.066 acc: 0.976 prec: 0.840 rec: 0.776 f1: 0.807\n",
      "\t[2  2848 0.37 sec] loss: 0.076 acc: 0.976 prec: 0.831 rec: 0.763 f1: 0.795\n",
      "\t[2  3204 0.37 sec] loss: 0.087 acc: 0.976 prec: 0.831 rec: 0.761 f1: 0.795\n",
      "\t[2  3560 0.37 sec] loss: 0.098 acc: 0.976 prec: 0.836 rec: 0.759 f1: 0.796\n",
      "Epoch 2 done in 13.47 min\n",
      "\t[3   356 0.37 sec] loss: 0.008 acc: 0.981 prec: 0.869 rec: 0.806 f1: 0.836\n",
      "\t[3   712 0.36 sec] loss: 0.017 acc: 0.981 prec: 0.867 rec: 0.806 f1: 0.835\n",
      "\t[3  1068 0.37 sec] loss: 0.026 acc: 0.980 prec: 0.860 rec: 0.807 f1: 0.833\n",
      "\t[3  1424 0.36 sec] loss: 0.035 acc: 0.979 prec: 0.856 rec: 0.798 f1: 0.826\n",
      "\t[3  1780 0.36 sec] loss: 0.044 acc: 0.979 prec: 0.852 rec: 0.792 f1: 0.821\n",
      "\t[3  2136 0.36 sec] loss: 0.053 acc: 0.978 prec: 0.847 rec: 0.786 f1: 0.815\n",
      "\t[3  2492 0.36 sec] loss: 0.063 acc: 0.977 prec: 0.846 rec: 0.784 f1: 0.813\n",
      "\t[3  2848 0.36 sec] loss: 0.073 acc: 0.978 prec: 0.846 rec: 0.786 f1: 0.815\n",
      "\t[3  3204 0.36 sec] loss: 0.083 acc: 0.977 prec: 0.842 rec: 0.777 f1: 0.808\n",
      "\t[3  3560 0.36 sec] loss: 0.093 acc: 0.977 prec: 0.845 rec: 0.769 f1: 0.805\n",
      "Epoch 3 done in 13.14 min\n",
      "\t[4   356 0.36 sec] loss: 0.008 acc: 0.982 prec: 0.873 rec: 0.823 f1: 0.847\n",
      "\t[4   712 0.36 sec] loss: 0.016 acc: 0.981 prec: 0.865 rec: 0.816 f1: 0.840\n",
      "\t[4  1068 0.36 sec] loss: 0.025 acc: 0.981 prec: 0.865 rec: 0.813 f1: 0.838\n",
      "\t[4  1424 0.36 sec] loss: 0.033 acc: 0.980 prec: 0.858 rec: 0.806 f1: 0.831\n",
      "\t[4  1780 0.36 sec] loss: 0.042 acc: 0.980 prec: 0.857 rec: 0.806 f1: 0.830\n",
      "\t[4  2136 0.36 sec] loss: 0.052 acc: 0.979 prec: 0.853 rec: 0.790 f1: 0.820\n",
      "\t[4  2492 0.36 sec] loss: 0.061 acc: 0.978 prec: 0.850 rec: 0.787 f1: 0.817\n",
      "\t[4  2848 0.36 sec] loss: 0.070 acc: 0.979 prec: 0.855 rec: 0.796 f1: 0.824\n",
      "\t[4  3204 0.36 sec] loss: 0.080 acc: 0.978 prec: 0.855 rec: 0.787 f1: 0.819\n",
      "\t[4  3560 0.36 sec] loss: 0.089 acc: 0.978 prec: 0.844 rec: 0.783 f1: 0.813\n",
      "Epoch 4 done in 12.97 min\n",
      "\t[5   356 0.36 sec] loss: 0.008 acc: 0.982 prec: 0.875 rec: 0.826 f1: 0.850\n",
      "\t[5   712 0.36 sec] loss: 0.016 acc: 0.982 prec: 0.874 rec: 0.819 f1: 0.845\n",
      "\t[5  1068 0.36 sec] loss: 0.024 acc: 0.980 prec: 0.865 rec: 0.812 f1: 0.838\n",
      "\t[5  1424 0.36 sec] loss: 0.032 acc: 0.981 prec: 0.863 rec: 0.817 f1: 0.839\n",
      "\t[5  1780 0.36 sec] loss: 0.041 acc: 0.979 prec: 0.851 rec: 0.810 f1: 0.830\n",
      "\t[5  2136 0.36 sec] loss: 0.050 acc: 0.980 prec: 0.860 rec: 0.810 f1: 0.834\n",
      "\t[5  2492 0.36 sec] loss: 0.059 acc: 0.980 prec: 0.859 rec: 0.807 f1: 0.832\n",
      "\t[5  2848 0.36 sec] loss: 0.068 acc: 0.979 prec: 0.858 rec: 0.800 f1: 0.828\n",
      "\t[5  3204 0.36 sec] loss: 0.077 acc: 0.979 prec: 0.853 rec: 0.787 f1: 0.819\n",
      "\t[5  3560 0.36 sec] loss: 0.086 acc: 0.978 prec: 0.848 rec: 0.785 f1: 0.815\n",
      "Epoch 5 done in 12.96 min\n"
     ]
    }
   ],
   "source": [
    "train(attn_model, optimizer, criterion, train_loader, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [  812 88.90 sec] loss: nan acc: 0.948 prec: 0.583 rec: 0.569 f1: 0.576\n"
     ]
    }
   ],
   "source": [
    "eval(attn_model, criterion, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 15 Epochs trained on the model with an Attention Layer (only last 5 shown above), we see\n",
    "\n",
    "#### Training F1 score is 0.815\n",
    "#### Validation F1 score is 0.576\n",
    "\n",
    "The model overfit quickly, and although training scoring is much higher, there is also a dip in Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying different configurations, as well as others such as an optimizer with a Weight decay, additional layers to the Attention, and other types of Word Embeddings, the final best model trained was:\n",
    "\n",
    "1. Neural Model with a 128-dim LSTM Layer, Attention Layer, and 2 Fully Connected Layers\n",
    "2. 300 Dimensional Fast Text word Embeddings\n",
    "3. Adam Optimizer with a 0.003 Learning Rate and no weight decay\n",
    "4. Trained on 5 Epochs\n",
    "\n",
    "To obtain a **0.771** Training F1 score and a **0.601** Validation F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing other Notebooks and other submissions on the Kaggle Project, good validation scores on the leaderboard are in the range of **0.70**. Most such implementations use enemble training, transfer learning, data augmentation by pulling in data from answers, and Transformers. I did not use any of these methods because my hardware resources are more limited. Transformers can be used, but I have not explored the concept enough to be able to implement them yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
